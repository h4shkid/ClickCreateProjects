const { ethers } = require('ethers')
require('dotenv').config()

// ERC-721 Transfer event signature
const TRANSFER_EVENT_SIGNATURE = '0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef'

// Test contract address (Good Vibes Club)
const TEST_CONTRACT = '0xb8ea78fcacef50d41375e44e6814ebba36bb33c4'

function createProvider() {
  const quickNodeEndpoint = process.env.NEXT_PUBLIC_QUICKNODE_ENDPOINT
  const alchemyKey = process.env.NEXT_PUBLIC_ALCHEMY_API_KEY
  
  if (quickNodeEndpoint) {
    console.log('üîó Using QuickNode endpoint')
    return new ethers.JsonRpcProvider(quickNodeEndpoint)
  } else if (alchemyKey) {
    console.log('üîó Using Alchemy endpoint')
    return new ethers.JsonRpcProvider(`https://eth-mainnet.g.alchemy.com/v2/${alchemyKey}`)
  } else {
    console.log('üîó Using public Ethereum endpoint')
    return new ethers.JsonRpcProvider('https://eth.llamarpc.com')
  }
}

const sleep = (ms) => new Promise(resolve => setTimeout(resolve, ms))

// Optimized block fetching (from our performance tests)
async function fetchBlocksOptimized(provider, blockNumbers) {
  const BATCH_SIZE = 15 // Optimal from tests
  const DELAY_MS = 200
  
  const allBlocks = []
  
  for (let i = 0; i < blockNumbers.length; i += BATCH_SIZE) {
    const batch = blockNumbers.slice(i, i + BATCH_SIZE)
    
    try {
      const blockPromises = batch.map(blockNum => 
        provider.getBlock(blockNum).catch(err => {
          console.warn(`Failed block ${blockNum}: ${err.message}`)
          return { number: blockNum, timestamp: Math.floor(Date.now() / 1000) }
        })
      )
      
      const blocks = await Promise.all(blockPromises)
      allBlocks.push(...blocks)
      
      if (i + BATCH_SIZE < blockNumbers.length) {
        await sleep(DELAY_MS)
      }
    } catch (error) {
      console.error('Batch error:', error.message)
    }
  }
  
  return allBlocks
}

// Optimized sync simulation
async function testOptimizedSync(provider, startBlock, endBlock) {
  console.log(`\nüöÄ Testing OPTIMIZED sync strategy`)
  console.log(`üìä Range: ${endBlock - startBlock + 1} blocks (${startBlock} to ${endBlock})`)
  
  const startTime = Date.now()
  let totalEvents = 0
  let errors = 0
  
  const CHUNK_SIZE = 500 // Optimal chunk size
  const CHUNK_DELAY = 300 // Delay between chunks
  
  // Process in chunks
  for (let fromBlock = startBlock; fromBlock <= endBlock; fromBlock += CHUNK_SIZE) {
    const toBlock = Math.min(fromBlock + CHUNK_SIZE - 1, endBlock)
    const chunkStartTime = Date.now()
    
    try {
      console.log(`üì¶ Processing chunk ${fromBlock}-${toBlock}`)
      
      // Fetch logs for this chunk
      const logs = await provider.getLogs({
        address: TEST_CONTRACT,
        fromBlock: fromBlock,
        toBlock: toBlock,
        topics: [TRANSFER_EVENT_SIGNATURE]
      })
      
      console.log(`   üìã Found ${logs.length} events`)
      
      if (logs.length > 0) {
        // Get unique block numbers for timestamp fetching
        const uniqueBlocks = [...new Set(logs.map(log => log.blockNumber))]
        console.log(`   üïê Fetching timestamps for ${uniqueBlocks.length} unique blocks`)
        
        // Optimized block timestamp fetching
        const blocks = await fetchBlocksOptimized(provider, uniqueBlocks)
        console.log(`   ‚úÖ Retrieved ${blocks.length} block timestamps`)
      }
      
      totalEvents += logs.length
      const chunkTime = Date.now() - chunkStartTime
      console.log(`   ‚è±Ô∏è  Chunk completed in ${chunkTime}ms`)
      
    } catch (error) {
      errors++
      console.error(`   ‚ùå Chunk failed: ${error.message}`)
      
      // Handle rate limiting
      if (error.message.includes('request limit') || error.message.includes('rate limit')) {
        console.log('   ‚è±Ô∏è  Rate limited, waiting 2 seconds...')
        await sleep(2000)
      }
    }
    
    // Delay between chunks
    if (fromBlock + CHUNK_SIZE <= endBlock) {
      await sleep(CHUNK_DELAY)
    }
  }
  
  const totalTime = Date.now() - startTime
  const totalBlocks = endBlock - startBlock + 1
  const blocksPerSecond = (totalBlocks / totalTime) * 1000
  const chunksProcessed = Math.ceil(totalBlocks / CHUNK_SIZE)
  
  console.log(`\n‚úÖ OPTIMIZED SYNC RESULTS:`)
  console.log(`   üìä Total time: ${totalTime}ms (${(totalTime/1000).toFixed(1)}s)`)
  console.log(`   üèÉ Blocks per second: ${blocksPerSecond.toFixed(1)}`)
  console.log(`   üìã Total events: ${totalEvents}`)
  console.log(`   üì¶ Chunks processed: ${chunksProcessed}`)
  console.log(`   ‚è±Ô∏è  Average per chunk: ${(totalTime/chunksProcessed).toFixed(1)}ms`)
  console.log(`   ‚úÖ Success rate: ${((chunksProcessed - errors) / chunksProcessed * 100).toFixed(1)}%`)
  
  // Estimate for larger sync
  const blocksPerHour = blocksPerSecond * 3600
  const millionBlockTime = (1000000 / blocksPerSecond / 60).toFixed(1)
  
  console.log(`\nüí° PERFORMANCE PROJECTIONS:`)
  console.log(`   üïê Blocks per hour: ${blocksPerHour.toLocaleString()}`)
  console.log(`   üìà Time for 1M blocks: ${millionBlockTime} minutes`)
  
  if (blocksPerSecond > 1000) {
    console.log(`   üöÄ Excellent! Can sync large ranges quickly`)
  } else if (blocksPerSecond > 500) {
    console.log(`   ‚úÖ Good performance for production use`)
  } else {
    console.log(`   ‚ö†Ô∏è  Consider further optimization for large syncs`)
  }
  
  return { totalTime, blocksPerSecond, totalEvents, errors, chunksProcessed }
}

// Run the test
async function runOptimizedTest() {
  console.log('üéØ Testing Optimized Sync Strategy')
  console.log('='.repeat(60))
  
  const provider = createProvider()
  
  try {
    // Test with a reasonable range - 2500 blocks (5 chunks)
    const currentBlock = await provider.getBlockNumber()
    const endBlock = currentBlock - 100
    const startBlock = endBlock - 2499 // 2500 blocks
    
    const result = await testOptimizedSync(provider, startBlock, endBlock)
    
    console.log('\n' + '='.repeat(60))
    console.log('üéâ OPTIMIZATION SUCCESS!')
    console.log('')
    console.log('üîß RECOMMENDED SETTINGS FOR PRODUCTION:')
    console.log('   ‚Ä¢ Chunk size: 500 blocks')
    console.log('   ‚Ä¢ Block batch size: 15')
    console.log('   ‚Ä¢ Chunk delay: 300ms')
    console.log('   ‚Ä¢ Block fetch delay: 200ms')
    console.log('')
    console.log(`üìà Expected performance: ${result.blocksPerSecond.toFixed(1)} blocks/second`)
    
  } catch (error) {
    console.error('‚ùå Test failed:', error)
  }
}

runOptimizedTest().catch(console.error)